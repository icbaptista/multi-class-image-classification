{"cells":[{"cell_type":"markdown","metadata":{"id":"4xOsd7MRiJ7B"},"source":["## Import libraries"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"9CIYyiUoiJ7G","executionInfo":{"status":"ok","timestamp":1687128293791,"user_tz":-60,"elapsed":4605,"user":{"displayName":"InÊs CaStRo","userId":"09580298180896956968"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import seaborn as sn\n","from sklearn.utils import shuffle\n","import matplotlib.pyplot as plt\n","import cv2\n","from tqdm import tqdm\n","import pandas as pd\n","from google.colab import drive"]},{"cell_type":"markdown","source":["Hardware specification"],"metadata":{"id":"9hMk8F6nrf7Z"}},{"cell_type":"code","source":["def check_gpu():\n","    import tensorflow as tf\n","    print(\"tf.test.is_built_with_cuda()\")\n","    print(tf.test.is_built_with_cuda())\n","\n","    print()\n","    print(\"tf.config.list_physical_devices('GPU')\")\n","    print(tf.config.list_physical_devices('GPU'))\n","\n","    print()\n","    print(\"tf.config.experimental.list_physical_devices('GPU')\")\n","    print(tf.config.experimental.list_physical_devices('GPU'))\n","\n","check_gpu() # Google Colab doesn't have a GPU?"],"metadata":{"id":"-r6oSWAk4XfA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Use CPU for training\n","#tf.config.set_visible_devices([], 'GPU')\n","\n","# Use GPU for training (if available)\n","tf.config.set_visible_devices(tf.config.list_physical_devices('GPU'), 'GPU')\n","\n","# Check the device placement\n","print(\"Device:\", tf.config.list_logical_devices())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4e3cFu__rfDA","executionInfo":{"status":"ok","timestamp":1687128329884,"user_tz":-60,"elapsed":309,"user":{"displayName":"InÊs CaStRo","userId":"09580298180896956968"}},"outputId":"5b4d59d0-1a2a-4e52-c238-27c2f9992126"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: [LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n"]}]},{"cell_type":"markdown","source":["#### Google Colab Google Drive mounting"],"metadata":{"id":"oA9GNpROrZp_"}},{"cell_type":"code","source":["drive.mount('/content/drive')\n","\n","# Set the path to the dataset folder\n","data_folder = '/content/drive/MyDrive/data'\n","\n","files = os.listdir(data_folder)\n","for file in files:\n","    print(file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Klr3cuRCiOPm","executionInfo":{"status":"ok","timestamp":1687126808281,"user_tz":-60,"elapsed":2663,"user":{"displayName":"InÊs CaStRo","userId":"09580298180896956968"}},"outputId":"e5972a7a-f754-45e1-baab-666aa7a02e17"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","train\n","test\n","pred\n"]}]},{"cell_type":"markdown","metadata":{"id":"HWxQPQh8iJ7J"},"source":["## Data loading and data preparation"]},{"cell_type":"code","source":["def get_image_info(image_path):\n","    image = cv2.imread(image_path)\n","\n","    if image is not None:\n","        # Image shape\n","        height, width, channels = image.shape\n","        print(\"Image shape:\", height, \"x\", width, \"x\", channels)\n","\n","        # Image size in bytes\n","        image_size = os.path.getsize(image_path)\n","        print(\"Image size:\", image_size, \"bytes\")\n","\n","        # Image data type\n","        image_dtype = image.dtype\n","        print(\"Image data type:\", image_dtype)\n","\n","        # Image color space\n","        if channels == 1:\n","            color_space = \"Grayscale\"\n","        elif channels == 3:\n","            color_space = \"RGB\"\n","        else:\n","            color_space = \"Unknown\"\n","        print(\"Image color space:\", color_space)\n","\n","    else:\n","        print(\"Failed to read the image:\", image_path)\n","\n","\n","get_image_info(\"/content/drive/MyDrive/data/train/buildings/10006.jpg\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HpJc3fn5muEg","executionInfo":{"status":"ok","timestamp":1687127167306,"user_tz":-60,"elapsed":416,"user":{"displayName":"InÊs CaStRo","userId":"09580298180896956968"}},"outputId":"5c489854-e74c-4fb0-e79b-bf02b7494caa"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Image shape: 150 x 150 x 3\n","Image size: 16802 bytes\n","Image data type: uint8\n","Image color space: RGB\n"]}]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGqo2RO3iJ7L","executionInfo":{"status":"ok","timestamp":1687127048109,"user_tz":-60,"elapsed":418,"user":{"displayName":"InÊs CaStRo","userId":"09580298180896956968"}},"outputId":"c6e4bcbd-b1f3-484f-a215-1ab3f222e2e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Images: [2191, 2271, 2404, 2512, 2274, 2382]\n","Test Images: [437, 477, 553, 525, 527, 501]\n"]}],"source":["from sklearn.utils import shuffle\n","from tqdm import tqdm\n","\n","class_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n","class_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n","nb_classes = len(class_names)\n","\n","def count_images(folder_path):\n","    count = 0\n","    for _, _, files in os.walk(folder_path):\n","        count += len(files)\n","    return count\n","\n","train_counts = [count_images(os.path.join(data_folder, 'train', class_name)) for class_name in class_names]\n","test_counts = [count_images(os.path.join(data_folder, 'test', class_name)) for class_name in class_names]\n","print(\"Train Images:\", train_counts)\n","print(\"Test Images:\", test_counts)"]},{"cell_type":"markdown","source":["### Load images in batches into RAM"],"metadata":{"id":"-COQeLmzthg3"}},{"cell_type":"code","source":["from skimage.io import imread\n","from skimage.transform import resize\n","from tensorflow.keras.utils import Sequence\n","from sklearn.utils import shuffle\n","\n","class My_Custom_Generator(Sequence):\n","    def __init__(self, folder_path, max_images, batch_size):\n","        self.folder_path = folder_path\n","        self.max_images = max_images\n","        self.batch_size = batch_size\n","        self.images, self.labels = self.load_images()\n","\n","    def load_images(self):\n","        print(\"Loading \" + self.folder_path)\n","        images = []\n","        labels = []\n","        images_per_folder = int(self.max_images / len(class_names))\n","\n","        for folder in tqdm(os.listdir(self.folder_path)):\n","            num_images_loaded_this_folder = 0\n","            if folder not in class_names_label:\n","                continue\n","            label = class_names_label[folder]\n","            # Iterate through each image in this folder\n","            for file in os.listdir(os.path.join(self.folder_path, folder)):\n","                if num_images_loaded_this_folder >= images_per_folder:\n","                    break\n","                # Get the path name of the image\n","                img_path = os.path.join(os.path.join(self.folder_path, folder), file)\n","                # Open the image\n","                image = imread(img_path)\n","                image = resize(image, (150, 150, 3))\n","                # Append the image and its corresponding label to the output\n","                images.append(image)\n","                labels.append(label)\n","                num_images_loaded_this_folder += 1\n","\n","        print(\"Loaded \" + self.folder_path)\n","        images, labels = shuffle(images, labels, random_state=3)\n","        images = np.array(images, dtype='float16') / 255.0\n","        labels = np.array(labels, dtype='int8')\n","        labels = tf.keras.utils.to_categorical(labels, num_classes=6)  # Convert labels to one-hot encoding\n","        return images, labels\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.images) / float(self.batch_size)))\n","\n","    def __getitem__(self, idx):\n","        batch_images = self.images[idx * self.batch_size: (idx + 1) * self.batch_size]\n","        batch_labels = self.labels[idx * self.batch_size: (idx + 1) * self.batch_size]\n","        return batch_images, batch_labels\n","\n","train_generator = My_Custom_Generator(os.path.join(data_folder, 'train'), max_images=7000, batch_size=64)\n","test_generator = My_Custom_Generator(os.path.join(data_folder, 'test'), max_images=1750, batch_size=64)\n","test_labels = test_generator.labels\n","\n","n_train = train_generator.labels.shape[0]\n","n_test = test_generator.labels.shape[0]\n","test_percentage = (n_test / (n_train + n_test)) * 100\n","\n","print(\"Train images:\", n_train)\n","print(\"Test images:\", n_test)\n","print(\"Test percentage: {}%\".format(round(test_percentage)))\n","\n","print(\"train_generator.images.shape:\", train_generator.images.shape)\n","print(\"train_generator.labels[:10]:\", train_generator.labels[:10])\n","print(\"test_generator.images.shape:\", test_generator.images.shape)\n","print(\"test_generator.labels[:10]:\", test_generator.labels[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JrM69sW8jUGi","executionInfo":{"status":"ok","timestamp":1687130007890,"user_tz":-60,"elapsed":112243,"user":{"displayName":"InÊs CaStRo","userId":"09580298180896956968"}},"outputId":"7c64f79d-b02e-4f31-9739-9443755fdc03"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading /content/drive/MyDrive/data/train\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6/6 [01:20<00:00, 13.50s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded /content/drive/MyDrive/data/train\n","Loading /content/drive/MyDrive/data/test\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6/6 [00:19<00:00,  3.25s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded /content/drive/MyDrive/data/test\n","Train images: 6996\n","Test images: 1746\n","Test percentage: 20%\n","train_generator.images.shape: (6996, 150, 150, 3)\n","train_generator.labels[:10]: [[0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]]\n","test_generator.images.shape: (1746, 150, 150, 3)\n","test_generator.labels[:10]: [[1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0.]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"_NmArR7uiJ7N"},"source":["## Multi-class Classification using Convulotinal Neural Networks (CNNs)\n","\n","We are using a pre-trained ResNet50 model is used for multi-class image classification. The ResNet50 model is loaded without its top layer and its layers are frozen to prevent them from being trained. A new sequential model is created on top of the base model, consisting of a flatten layer, a dense layer with ReLU activation, and a dense layer with softmax activation for the output. The model is compiled with the Adam optimizer and categorical cross-entropy loss. The training and test images are preprocessed by scaling their values between 0 and 1. The model is then trained using the training images and labels, with a batch size of 32 and for 10 epochs. The validation data is provided using the test images and labels. After training, the model is saved for future use."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRDUg1JyiJ7P","outputId":"f73383fd-505c-491f-b6ba-149616eb9076"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 5, 5, 2048)        23587712  \n","                                                                 \n"," global_average_pooling2d_1   (None, 2048)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_12 (Dense)            (None, 256)               524544    \n","                                                                 \n"," dense_13 (Dense)            (None, 6)                 1542      \n","                                                                 \n","=================================================================\n","Total params: 24,113,798\n","Trainable params: 526,086\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n","Epoch 1/10\n","110/110 [==============================] - 606s 5s/step - loss: 1.8152 - accuracy: 0.1631 - val_loss: 1.8253 - val_accuracy: 0.1667\n","Epoch 2/10\n","110/110 [==============================] - 574s 5s/step - loss: 1.8158 - accuracy: 0.1645 - val_loss: 1.8278 - val_accuracy: 0.1667\n","Epoch 3/10\n","110/110 [==============================] - ETA: 0s - loss: 1.8098 - accuracy: 0.1682"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n","from sklearn.utils import shuffle\n","\n","# Load the ResNet50 model without the top layer\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n","\n","# Freeze the base model's layers\n","base_model.trainable = False\n","\n","# Create a new model on top of the base model\n","model = Sequential()\n","model.add(base_model)\n","model.add(GlobalAveragePooling2D())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(6, activation='softmax'))  # Assuming 6 scene classes\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()\n","\n","# Rest of your code for data loading and generator initialization...\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=10,\n","    validation_data=test_generator\n",")\n","\n","# Save the model\n","model.save('scene_classification_model.h5')"]},{"cell_type":"markdown","source":["## Learning Curve and Confusion Matrix"],"metadata":{"id":"xsYm9hGhzDyf"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sn\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_loss_accuracy(history):\n","    if not isinstance(history, dict):\n","        history = history.history\n","\n","    num_epochs = len(history[\"accuracy\"])\n","    x_values = range(1, num_epochs + 1)  # Generate x-axis values starting from 1\n","\n","    # Plot accuracy\n","    plt.plot(x_values, history['accuracy'], label = \"Train acc\")\n","    plt.plot(x_values, history['val_accuracy'], label = \"Validation acc\")\n","    plt.title(\"Learning curve\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()\n","    plt.xticks(range(0, num_epochs + 1, 2), range(0, num_epochs + 1, 2))\n","    plt.show()\n","\n","    # Plot loss function\n","    plt.plot(x_values, history['loss'], label = \"Train loss\")\n","    plt.plot(x_values, history['val_loss'], label = \"Validation loss\")\n","    plt.title(\"Learning curve\")\n","    plt.ylabel(\"Loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()\n","    plt.xticks(range(0, num_epochs + 1, 2), range(0, num_epochs + 1, 2))\n","    plt.show()\n","\n","def plot_confusion_matrix(model, verbose=1):\n","    class_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\" ]\n","    preds = model.predict(test_generator, workers=8, verbose=verbose)\n","    preds_labels = np.argmax(preds, axis=1)\n","    cm = confusion_matrix(test_labels, preds_labels)\n","    ax = plt.axes()\n","    sn.heatmap(cm, annot=True, fmt=\"d\",\n","               annot_kws={\"size\": 10},\n","               xticklabels=class_names,\n","               yticklabels=class_names, ax = ax)\n","    ax.set_title('Confusion matrix')\n","    ax.set_xlabel('Predicted')\n","    ax.set_ylabel('Actual')\n","    plt.show()"],"metadata":{"id":"-rm9XNAczHcc"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}