{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sn\n",
    "from sklearn.utils import shuffle           \n",
    "import matplotlib.pyplot as plt             \n",
    "import cv2                                 \n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\" ]\n",
    "train_counts = []\n",
    "test_counts = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    path = \"data/train/\" + class_name\n",
    "    num_images = 0\n",
    "    for _, _, files in os.walk(path):\n",
    "        num_images += len(files)\n",
    "    train_counts.append(num_images)\n",
    "    \n",
    "    path = \"data/test/\" + class_name\n",
    "    num_images = 0\n",
    "    for _, _, files in os.walk(path):\n",
    "        num_images += len(files)\n",
    "    test_counts.append(num_images)\n",
    "train_counts = np.array(train_counts)\n",
    "test_counts = np.array(test_counts)\n",
    "\n",
    "num_train = np.sum(train_counts)\n",
    "num_test = np.sum(test_counts)\n",
    "test_percentage = round(num_test / (num_train+num_test) * 100)\n",
    "print(\"Train images: \" + str(num_train))\n",
    "print(\"Test images: \" + str(num_test))\n",
    "print(\"Test percentage: \" + str(test_percentage) + \"%\")\n",
    "\n",
    "class_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\" ]\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "def load_images(folder_path, max_images=1000000, target_size=(150,150)):\n",
    "    print(\"Loading \" + folder_path)\n",
    "    images = []\n",
    "    labels = []\n",
    "    images_per_folder = int(max_images / 6) # rounds down\n",
    "    \n",
    "    for folder in os.listdir(folder_path):\n",
    "        num_images_loaded_this_folder = 0\n",
    "        label = class_names_label[folder]\n",
    "        # Iterate through each image in this folder\n",
    "        for file in tqdm(os.listdir(os.path.join(folder_path, folder))):\n",
    "            # Get the path name of the image\n",
    "            img_path = os.path.join(os.path.join(folder_path, folder), file)\n",
    "            # Open and resize the img\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, target_size) \n",
    "            # Append the image and its corresponding label to the output\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "            num_images_loaded_this_folder += 1\n",
    "            if num_images_loaded_this_folder >= images_per_folder:\n",
    "                break\n",
    "                \n",
    "    print(\"Loaded \" + folder_path)\n",
    "    return np.array(images, dtype = 'float16'), np.array(labels, dtype = 'int8')\n",
    "\n",
    "target_size = (75,75)\n",
    "train_images, train_labels = load_images(\"data/train\", max_images=7000, target_size=target_size)\n",
    "test_images, test_labels = load_images(\"data/test\", max_images=1750, target_size=target_size)\n",
    "\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=3)\n",
    "\n",
    "# Normalization\n",
    "train_images = train_images / 255.0 \n",
    "test_images = test_images / 255.0\n",
    "\n",
    "n_train = train_labels.shape[0]\n",
    "n_test = test_labels.shape[0]\n",
    "test_percentage = (n_test/(n_train+n_test)) * 100\n",
    "\n",
    "print(\"Image size:\", target_size)\n",
    "print (\"Train images: {}\".format(n_train))\n",
    "print (\"Test images: {}\".format(n_test))\n",
    "print(\"Test percentage: {}%\".format(round(test_percentage)))\n",
    "\n",
    "print(\"train_images.shape\", train_images.shape)\n",
    "print(\"train_labels[:10]\", train_labels[:10])\n",
    "print(\"test_images.shape\", test_images.shape)\n",
    "print(\"test_labels[:10]\", test_labels[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification using Convulotinal Neural Networks (CNNs)\n",
    "\n",
    "We are using a pre-trained ResNet50 model is used for multi-class image classification. The ResNet50 model is loaded without its top layer and its layers are frozen to prevent them from being trained. A new sequential model is created on top of the base model, consisting of a flatten layer, a dense layer with ReLU activation, and a dense layer with softmax activation for the output. The model is compiled with the Adam optimizer and categorical cross-entropy loss. The training and test images are preprocessed by scaling their values between 0 and 1. The model is then trained using the training images and labels, with a batch size of 32 and for 10 epochs. The validation data is provided using the test images and labels. After training, the model is saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the ResNet50 model without the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(75, 75, 3))\n",
    "\n",
    "# Freeze the base model's layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a new model on top of the base model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))  # Assuming 6 scene classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images,\n",
    "    tf.keras.utils.to_categorical(train_labels, num_classes=nb_classes),\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_data=(test_images, tf.keras.utils.to_categorical(test_labels, num_classes=nb_classes))\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('scene_classification_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
