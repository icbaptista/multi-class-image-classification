{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOsd7MRiJ7B"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CIYyiUoiJ7G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sn\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hMk8F6nrf7Z"
      },
      "source": [
        "Hardware specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r6oSWAk4XfA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def check_gpu():\n",
        "    print(\"tf.test.is_built_with_cuda()\")\n",
        "    print(tf.test.is_built_with_cuda())\n",
        "\n",
        "    print()\n",
        "    print(\"tf.config.list_physical_devices('GPU')\")\n",
        "    print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "    print()\n",
        "    print(\"tf.config.experimental.list_physical_devices('GPU')\")\n",
        "    print(tf.config.experimental.list_physical_devices('GPU'))\n",
        "\n",
        "check_gpu() # Google Colab doesn't have a GPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e3cFu__rfDA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Use CPU for training\n",
        "#tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "# Use GPU for training (if available)\n",
        "tf.config.set_visible_devices(tf.config.list_physical_devices('GPU'), 'GPU')\n",
        "\n",
        "# Check the device placement\n",
        "print(\"Device:\", tf.config.list_logical_devices())\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "if gpus:\n",
        "  try:\n",
        "    # Enable memory growth for each GPU\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA9GNpROrZp_"
      },
      "source": [
        "#### Google Colab Google Drive mounting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Klr3cuRCiOPm"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the dataset folder\n",
        "data_folder = '/content/drive/MyDrive/data'\n",
        "glob.glob('..data/*')\n",
        "#data_folder = 'data'\n",
        "\n",
        "files = os.listdir(data_folder)\n",
        "for file in files:\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWxQPQh8iJ7J"
      },
      "source": [
        "## Data loading and data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpJc3fn5muEg"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_image_info(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Image shape\n",
        "        height, width, channels = image.shape\n",
        "        print(\"Image shape:\", height, \"x\", width, \"x\", channels)\n",
        "\n",
        "        # Image size in bytes\n",
        "        image_size = os.path.getsize(image_path)\n",
        "        print(\"Image size:\", image_size, \"bytes\")\n",
        "\n",
        "        # Image data type\n",
        "        image_dtype = image.dtype\n",
        "        print(\"Image data type:\", image_dtype)\n",
        "\n",
        "        # Image color space\n",
        "        if channels == 1:\n",
        "            color_space = \"Grayscale\"\n",
        "        elif channels == 3:\n",
        "            color_space = \"RGB\"\n",
        "        else:\n",
        "            color_space = \"Unknown\"\n",
        "        print(\"Image color space:\", color_space)\n",
        "\n",
        "        # Display the image\n",
        "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"Failed to read the image:\", image_path)\n",
        "\n",
        "\n",
        "get_image_info(\"/content/drive/MyDrive/data/train/buildings/10006.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGqo2RO3iJ7L"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
        "class_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "nb_classes = len(class_names)\n",
        "train_folders = [os.path.join(data_folder, 'train', class_name) for class_name in class_names]\n",
        "test_folders = [os.path.join(data_folder, 'test', class_name) for class_name in class_names]\n",
        "\n",
        "def count_images(folder_path):\n",
        "    count = 0\n",
        "    for _, _, files in os.walk(folder_path):\n",
        "        count += len(files)\n",
        "    return count\n",
        "\n",
        "train_counts = sum([count_images(os.path.join(data_folder, 'train', class_name)) for class_name in class_names])\n",
        "test_counts = sum([count_images(os.path.join(data_folder, 'test', class_name)) for class_name in class_names])\n",
        "\n",
        "print(\"Total Train Images:\", train_counts)\n",
        "print(\"Total Test Images:\", test_counts)\n",
        "\n",
        "def prepare_dataset(path, label):\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "    all_images_path = glob.glob(path + '/*.jpg')\n",
        "    for img_path in all_images_path:\n",
        "        img = load_img(img_path, target_size=(150, 150))\n",
        "        img = img_to_array(img)\n",
        "        img = img / 255.0\n",
        "        x_data.append(img)\n",
        "        y_data.append(label)\n",
        "    return np.array(x_data), np.array(y_data)\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "test_labels = []\n",
        "\n",
        "for folder, label in zip(train_folders, range(nb_classes)):\n",
        "    trainX, trainY = prepare_dataset(folder, label)\n",
        "    x_train.extend(trainX)\n",
        "    y_train.extend(trainY)\n",
        "\n",
        "for folder, label in zip(test_folders, range(nb_classes)):\n",
        "    testX, testY = prepare_dataset(folder, label)\n",
        "    x_test.extend(testX)\n",
        "    y_test.extend(testY)\n",
        "    test_labels.extend([label] * len(testY))\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "y_train = to_categorical(y_train, num_classes=nb_classes)\n",
        "y_test = to_categorical(y_test, num_classes=nb_classes)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "y_val = to_categorical(y_val, num_classes=nb_classes)\n",
        "\n",
        "test_percentage = (test_counts / (train_counts + test_counts)) * 100\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "print(\"Test Percentage:\", test_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3jSfOzIPokN"
      },
      "source": [
        "## Load Images and Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SnCCETXPsGm"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def load_images(self):\n",
        "        print(\"Loading \" + self.folder_path)\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        num_images_loaded = 0  # Counter for total images loaded\n",
        "\n",
        "        # Calculate images per folder based on the total number of folders in the dataset\n",
        "        images_per_folder = int(self.max_images / len(os.listdir(self.folder_path)))\n",
        "\n",
        "        for folder in tqdm(os.listdir(self.folder_path)):\n",
        "            num_images_loaded_this_folder = 0\n",
        "            if folder not in class_names_label:\n",
        "                continue\n",
        "            label = class_names_label[folder]\n",
        "            # Iterate through each image in this folder\n",
        "            for file in os.listdir(os.path.join(self.folder_path, folder)):\n",
        "                if num_images_loaded_this_folder >= images_per_folder:\n",
        "                    break\n",
        "                # Get the path name of the image\n",
        "                img_path = os.path.join(os.path.join(self.folder_path, folder), file)\n",
        "                # Open the image\n",
        "                image = imread(img_path)\n",
        "                image = resize(image, (150, 150, 3))\n",
        "                # Append the image and its corresponding label to the output\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                num_images_loaded_this_folder += 1\n",
        "                num_images_loaded += 1\n",
        "\n",
        "        print(\"Loaded \" + self.folder_path)\n",
        "        images, labels = shuffle(images, labels, random_state=3)\n",
        "        images = np.array(images, dtype='float16') / 255.0\n",
        "        labels = np.array(labels, dtype='int8')\n",
        "        labels = tf.keras.utils.to_categorical(labels, num_classes=6)  # Convert labels to one-hot encoding\n",
        "        return images, labels\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-COQeLmzthg3"
      },
      "source": [
        "### Load images in batches into RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrM69sW8jUGi"
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "class My_Custom_Generator(Sequence):\n",
        "    def __init__(self, folder_path, max_images, batch_size):\n",
        "        self.folder_path = folder_path\n",
        "        self.max_images = max_images\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_images = self.images[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
        "        batch_labels = self.labels[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "train_generator = My_Custom_Generator(os.path.join(data_folder, 'train'), max_images=7000, batch_size=64)\n",
        "test_generator = My_Custom_Generator(os.path.join(data_folder, 'test'), max_images=1750, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NmArR7uiJ7N"
      },
      "source": [
        "## Multi-class Classification using Convulotinal Neural Networks (CNNs)\n",
        "\n",
        "We are using a pre-trained ResNet50 model is used for multi-class image classification. The ResNet50 model is loaded without its top layer and its layers are frozen to prevent them from being trained. A new sequential model is created on top of the base model, consisting of a flatten layer, a dense layer with ReLU activation, and a dense layer with softmax activation for the output. The model is compiled with the Adam optimizer and categorical cross-entropy loss. The training and test images are preprocessed by scaling their values between 0 and 1. The model is then trained using the training images and labels, with a batch size of 32 and for 10 epochs. The validation data is provided using the test images and labels. After training, the model is saved for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRDUg1JyiJ7P"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, DenseNet121,  VGG16, InceptionV3\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Model,load_model, Sequential\n",
        "from tensorflow.keras.layers import  GlobalAveragePooling2D, Dropout, Dense, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import  Adam\n",
        "\n",
        "def train_model( architecture, batch_size, learning_rate=0.001):\n",
        "    # Load the specified base\n",
        "    if architecture == 'resnet50':\n",
        "        print(\"Resnet-50 CNN Model\")\n",
        "        print(\"batch_size={0}\".format(batch_size))\n",
        "        model_name = 'scene_classification_resnet.h5'\n",
        "        # Load the pre-trained ResNet-50 model\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "        # Freeze the base model's layers\n",
        "        #base_model.trainable = False\n",
        "        for layer in base_model.layers[:-15]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        # Create a new model on top of the base model\n",
        "        model = tf.keras.Sequential([\n",
        "            base_model,\n",
        "            GlobalAveragePooling2D(),\n",
        "            Dropout(0.25),\n",
        "            Dense(6, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        # Compile the model\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.summary()\n",
        "    elif architecture == 'densenet121':\n",
        "        print(\"Densenet-121 CNN Model\")\n",
        "        print(\"batch_size={0}\".format(batch_size))\n",
        "        model_name = 'scene_classification_densenet.h5'\n",
        "        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "        # Freeze the base model's layers\n",
        "        # base_model.trainable = False\n",
        "        for layer in base_model.layers[:-10]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        # Create a new model on top of the base model\n",
        "        model = Sequential()\n",
        "        model.add(base_model)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        model.add(Dense(6, activation='softmax'))  # Assuming 6 scene classes\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "    elif architecture == 'vgg16':\n",
        "        print(\"VGG16 CNN Model\")\n",
        "        print(\"batch_size={0}\".format(batch_size))\n",
        "        model_name = 'scene_classification_vgg16.h5'\n",
        "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "        # Freeze the base model's layers\n",
        "        # base_model.trainable = False\n",
        "        for layer in base_model.layers[:-6]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        # Create a new model on top of the base model\n",
        "        model = Sequential()\n",
        "        model.add(base_model)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        model.add(Dense(6, activation='softmax'))  # Assuming 6 scene classes\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "    elif architecture == 'inceptionv3':\n",
        "        print(\"InceptionV3 CNN Model\")\n",
        "        print(\"batch_size={0}\".format(batch_size))\n",
        "        model_name = 'scene_classification_inceptionv3.h5'\n",
        "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "        # Freeze the base model's layers\n",
        "        # base_model.trainable = False\n",
        "        for layer in base_model.layers[:-4]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        # Create a new model on top of the base model\n",
        "        model = Sequential()\n",
        "        model.add(base_model)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        model.add(Dense(6, activation='softmax'))  # Assuming 6 scene classes\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "    else:\n",
        "        raise ValueError(\"Invalid architecture specified. Supported architectures: 'resnet50', 'densenet121'.\")\n",
        "\n",
        "    # Calculate the number of steps (batches) per epoch for training and validation\n",
        "    train_steps = len(x_train)\n",
        "    val_steps = len(x_test)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        steps_per_epoch=train_steps,\n",
        "        epochs=8,\n",
        "        validation_data=(x_test, y_test),\n",
        "        validation_steps=val_steps\n",
        "    )\n",
        "\n",
        "    # Save the model\n",
        "    model.save(model_name)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(x_test, steps=val_steps)\n",
        "\n",
        "    # Print the test accuracy\n",
        "    print(\"Test Loss:\", test_loss)\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4Ib72fVL9VG"
      },
      "source": [
        "## Learning Curve and Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzihPOQJL4Ni"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_loss_accuracy(history):\n",
        "    if not isinstance(history, dict):\n",
        "        history = history.history\n",
        "\n",
        "    num_epochs = len(history[\"accuracy\"])\n",
        "    x_values = range(1, num_epochs + 1)  # Generate x-axis values starting from 1\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.plot(x_values, history['accuracy'], label = \"Train acc\")\n",
        "    plt.plot(x_values, history['val_accuracy'], label = \"Validation acc\")\n",
        "    plt.title(\"Learning curve\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "    plt.xticks(range(0, num_epochs + 1, 2), range(0, num_epochs + 1, 2))\n",
        "    plt.show()\n",
        "\n",
        "    # Plot loss function\n",
        "    plt.plot(x_values, history['loss'], label = \"Train loss\")\n",
        "    plt.plot(x_values, history['val_loss'], label = \"Validation loss\")\n",
        "    plt.title(\"Learning curve\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "    plt.xticks(range(0, num_epochs + 1, 2), range(0, num_epochs + 1, 2))\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(model, verbose=1):\n",
        "    class_names = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\" ]\n",
        "    preds = model.predict(x_test, workers=8, verbose=verbose)\n",
        "    preds_labels = np.argmax(preds, axis=1)\n",
        "    cm = confusion_matrix(test_labels, preds_labels)\n",
        "    ax = plt.axes()\n",
        "    sn.heatmap(cm, annot=True, fmt=\"d\",\n",
        "               annot_kws={\"size\": 10},\n",
        "               xticklabels=class_names,\n",
        "               yticklabels=class_names, ax = ax)\n",
        "    ax.set_title('Confusion matrix')\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('Actual')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2Y8J-4wL_N0"
      },
      "source": [
        "## Load or Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t67UDBpaLCPy",
        "outputId": "85f3740d-f5f7-45fe-9929-3c4b37d217bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resnet-50 CNN Model\n",
            "batch_size=32\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 5, 5, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 12294     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 12,294\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "11227/11227 [==============================] - 1770s 157ms/step - loss: 1.4913 - accuracy: 0.3844 - val_loss: 1.2610 - val_accuracy: 0.5086\n",
            "Epoch 2/8\n",
            "11227/11227 [==============================] - 1763s 157ms/step - loss: 1.2895 - accuracy: 0.4854 - val_loss: 1.1349 - val_accuracy: 0.5877\n",
            "Epoch 3/8\n",
            "11227/11227 [==============================] - 1764s 157ms/step - loss: 1.2130 - accuracy: 0.5130 - val_loss: 1.0919 - val_accuracy: 0.6007\n",
            "Epoch 4/8\n",
            "11227/11227 [==============================] - 1758s 157ms/step - loss: 1.1766 - accuracy: 0.5363 - val_loss: 1.0752 - val_accuracy: 0.5732\n",
            "Epoch 5/8\n",
            "11227/11227 [==============================] - 1756s 156ms/step - loss: 1.1448 - accuracy: 0.5446 - val_loss: 1.0339 - val_accuracy: 0.6053\n",
            "Epoch 6/8\n",
            "11227/11227 [==============================] - 1764s 157ms/step - loss: 1.1273 - accuracy: 0.5544 - val_loss: 1.0599 - val_accuracy: 0.5447\n",
            "Epoch 7/8\n",
            "11227/11227 [==============================] - 1741s 155ms/step - loss: 1.1152 - accuracy: 0.5539 - val_loss: 1.0111 - val_accuracy: 0.5993\n",
            "Epoch 8/8\n",
            " 3452/11227 [========>.....................] - ETA: 15:32 - loss: 1.1130 - accuracy: 0.5556"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "def save_model_and_history(model, model_file, history, history_file):\n",
        "    print(\"Saving \" + model_file + \" and history\")\n",
        "    model.save(model_file)\n",
        "    with open(history_file, 'wb') as hist:\n",
        "        pickle.dump(history.history, hist)\n",
        "    print(\"Saved \" + model_file + \" and history\")\n",
        "\n",
        "def load_model_and_history(model_file, model_history_file):\n",
        "    if not os.path.exists(model_file) or not os.path.exists(model_history_file):\n",
        "        return None, None\n",
        "\n",
        "    print(\"Loading model \" + model_file + \" and history\")\n",
        "    model = load_model(model_file)\n",
        "    with open(model_history_file, \"rb\") as hist_file:\n",
        "        history = pickle.load(hist_file)\n",
        "    print(\"Loaded model \" + model_file + \" and history\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def get_test_acc(model, verbose=1):\n",
        "    preds = model.predict(x_test, workers=8, verbose=verbose)\n",
        "    preds_labels = np.argmax(preds, axis=1)\n",
        "    cm = confusion_matrix(test_labels, preds_labels)\n",
        "\n",
        "    sum_diagonal = np.trace(cm)\n",
        "    acc = sum_diagonal / np.sum(cm)\n",
        "    return acc\n",
        "\n",
        "def get_test_accs(model, verbose=1):\n",
        "    preds = model.predict(x_test, workers=8, verbose=verbose)\n",
        "    preds_labels = np.argmax(preds, axis=1)\n",
        "    cm = confusion_matrix(test_labels, preds_labels)\n",
        "\n",
        "    accuracies = []\n",
        "    for i in range(cm.shape[0]):\n",
        "        tp = cm[i,i]\n",
        "        fp = np.sum(cm[:, i]) - tp\n",
        "        tn = np.sum(cm) - np.sum(cm[:, i]) - np.sum(cm[i, :]) + tp\n",
        "        fn = np.sum(cm[i, :]) - tp\n",
        "        acc_class = (tp + tn) / (tp+fp+tn+fn)\n",
        "        accuracies.append(acc_class)\n",
        "\n",
        "    return accuracies\n",
        "\n",
        "def evaluate_model(model):\n",
        "    print(\"Evaluating on test set...\")\n",
        "    acc = get_test_acc(model, verbose=0)\n",
        "    print(\"Test set accuracy: {:.2f}%\".format(acc*100))\n",
        "    accs = get_test_accs(model, verbose=0)\n",
        "    classes = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
        "    for i in range(len(classes)):\n",
        "        print(\"Test set accuracy for {}: {:.2f}%\".format(classes[i], accs[i]*100))\n",
        "\n",
        "\n",
        "def train_model_load_save_and_analysis(batch_size, model_file, architecture):\n",
        "    history_file = model_file[0:-3] + \"_history\"\n",
        "    model, history = load_model_and_history(model_file, history_file)\n",
        "    was_model_loaded = model != None and history != None\n",
        "\n",
        "    if was_model_loaded:\n",
        "        evaluate_model(model)\n",
        "    else:\n",
        "        # Couldn't load model, so train it now and save it\n",
        "        # model, history = train_model(batch_size=32, architecture='resnet50', learning_rate=0.001)\n",
        "        model, history = train_model(architecture, batch_size=32, learning_rate=0.001)\n",
        "        save_model_and_history(model, model_file, history, history_file)\n",
        "\n",
        "    plot_confusion_matrix(model)\n",
        "    plot_loss_accuracy(history)\n",
        "    return model, history\n",
        "\n",
        "# Create the models folder if doesnt exist\n",
        "if not os.path.exists(\"otherarchitectures\"):\n",
        "    os.makedirs(\"otherarchitectures\", exist_ok=True)\n",
        "\n",
        "batch_sizes = [32, 64, 128]\n",
        "model_file = \"otherarchitectures/resnetmodel_v3_{0}.h5\".format(batch_sizes[0])\n",
        "model, history = train_model_load_save_and_analysis(batch_sizes[0], model_file, architecture='resnet50')\n",
        "# model, history = train_model_load_save_and_analysis(batch_sizes[0], model_file, architecture='densenet121')\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AnJ1g7HZdDS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iBTNjEXMCsE"
      },
      "source": [
        "## Code to test if I can get the visual ouput of Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWIz3OiD-m8Z"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create an intermediate model to extract feature maps\n",
        "feature_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "\n",
        "# Choose an image from your dataset\n",
        "image = train_generator.images[0]  # Choose an image from the training set\n",
        "\n",
        "# Preprocess the image\n",
        "preprocessed_image = train_generator.images[0]  # Preprocess the image if necessary\n",
        "\n",
        "# Reshape the image to match the input shape of the model\n",
        "reshaped_image = np.expand_dims(preprocessed_image, axis=0)\n",
        "\n",
        "# Extract the feature maps using the intermediate model\n",
        "feature_maps = feature_extractor.predict(reshaped_image)\n",
        "\n",
        "# Plot the original image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image)\n",
        "plt.title('Original Image')\n",
        "\n",
        "# Plot the input feature map\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(feature_maps[0, :, :, 0], cmap='gray')  # Assuming grayscale feature map\n",
        "plt.title('Input Feature Map')\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}